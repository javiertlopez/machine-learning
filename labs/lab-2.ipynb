{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python395jvsc74a57bd0f9e85be1229148adc6ebaac8428b2405c32e294c2e11c83343830273441b866e",
   "display_name": "Python 3.9.5 64-bit ('venv': venv)",
   "language": "python"
  },
  "metadata": {
   "interpreter": {
    "hash": "a081492f977d15fe2cc5c47b1fe307f337ae9e296dcaffa5436ed2570310f973"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Lab 2: Iris\n",
    "\n",
    "## Overview\n",
    "\n",
    "Iris Flowers Classification with Logistical Regresion.\n",
    "\n",
    "Team\n",
    "- Victor Manuel Castrejon Morales\n",
    "- Hiram Javier Torres Lopez"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Training/Test\n",
    "\n",
    "The first step is to download the dataset from the sklearn collection.\n",
    "\n",
    "Then we are going to split the dataset into an `X` matrix with atributes, and an array `y` with labels with the following distribution:\n",
    "\n",
    "Training    | Test  |\n",
    ":-----------|-------|\n",
    "30          | 70    |\n",
    "50          | 50    |\n",
    "70          | 30    |"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Initial setup\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 39,
   "outputs": []
  },
  {
   "source": [
    "### 30/70"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.70, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', penalty='none', random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", random_state=42, penalty=\"none\")\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "source": [
    "y_proba = log_reg.predict_proba(X_test)\n",
    "y_predict = np.argmax(y_proba, axis=1)\n",
    "\n",
    "accuracy_score = np.mean(y_predict == y_test)\n",
    "accuracy_score"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 42,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9619047619047619"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ]
  },
  {
   "source": [
    "### 50/50"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', penalty='none', random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "y_proba = log_reg.predict_proba(X_test)\n",
    "y_predict = np.argmax(y_proba, axis=1)\n",
    "\n",
    "accuracy_score = np.mean(y_predict == y_test)\n",
    "accuracy_score"
   ]
  },
  {
   "source": [
    "### 70/30"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', penalty='none', random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "y_proba = log_reg.predict_proba(X_test)\n",
    "y_predict = np.argmax(y_proba, axis=1)\n",
    "\n",
    "accuracy_score = np.mean(y_predict == y_test)\n",
    "accuracy_score"
   ]
  },
  {
   "source": [
    "Training    | Test  | Accuracy score    |\n",
    ":-----------|-------| ------------------|\n",
    "30          | 70    | 0.9619            |\n",
    "50          | 50    | 0.91              |\n",
    "70          | 30    | 1.0               |\n",
    "\n",
    "From those results, we can confirm the best way to split our dataset for LogisticRegression, **without any penalization**, is 70 training and 30 test."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Single feature classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "iris.feature_names\n"
   ]
  },
  {
   "source": [
    "**sepal length (cm)**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sepal_length = X[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "x_sepal_length.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_sepal_length, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Reshape your data either using array.reshape(-1, 1) if your data has a single feature.\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', penalty='none', random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "log_reg = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", random_state=42, penalty=\"none\")\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6888888888888889"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "y_proba = log_reg.predict_proba(X_test)\n",
    "y_predict = np.argmax(y_proba, axis=1)\n",
    "\n",
    "accuracy_score = np.mean(y_predict == y_test)\n",
    "accuracy_score"
   ]
  },
  {
   "source": [
    "**sepal width (cm)**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sepal_width = X[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_sepal_width, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Reshape your data either using array.reshape(-1, 1) if your data has a single feature.\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', penalty='none', random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5555555555555556"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "y_proba = log_reg.predict_proba(X_test)\n",
    "y_predict = np.argmax(y_proba, axis=1)\n",
    "\n",
    "accuracy_score = np.mean(y_predict == y_test)\n",
    "accuracy_score"
   ]
  },
  {
   "source": [
    "**petal length (cm)**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_petal_length = X[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_petal_length, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Reshape your data either using array.reshape(-1, 1) if your data has a single feature.\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', penalty='none', random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "y_proba = log_reg.predict_proba(X_test)\n",
    "y_predict = np.argmax(y_proba, axis=1)\n",
    "\n",
    "accuracy_score = np.mean(y_predict == y_test)\n",
    "accuracy_score"
   ]
  },
  {
   "source": [
    "**petal width (cm)**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_petal_width = X[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_petal_width, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Reshape your data either using array.reshape(-1, 1) if your data has a single feature.\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', penalty='none', random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "y_proba = log_reg.predict_proba(X_test)\n",
    "y_predict = np.argmax(y_proba, axis=1)\n",
    "\n",
    "accuracy_score = np.mean(y_predict == y_test)\n",
    "accuracy_score"
   ]
  },
  {
   "source": [
    "Feature             | Accuracy score    |\n",
    ":-------------------| ------------------|\n",
    "sepal length (cm)   | 0.6888            |\n",
    "sepal width (cm)    | 0.5555            |\n",
    "petal length (cm)   | 1.0               |\n",
    "petal width (cm)    | 1.0               |\n",
    "\n",
    "From those results, we can confirm petal length and width are the best features for LogisticRegression, **without any penalization**."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Double feature classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "source": [
    "**sepal length (cm), sepal width (cm)**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered_train = X_train[:, [0, 1]]\n",
    "X_filtered_test = X_test[:, [0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', penalty='none', random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "log_reg.fit(X_filtered_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8222222222222222"
      ]
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "y_proba = log_reg.predict_proba(X_filtered_test)\n",
    "y_predict = np.argmax(y_proba, axis=1)\n",
    "\n",
    "accuracy_score = np.mean(y_predict == y_test)\n",
    "accuracy_score"
   ]
  },
  {
   "source": [
    "**sepal length (cm), petal length (cm)**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered_train = X_train[:, [0, 2]]\n",
    "X_filtered_test = X_test[:, [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', penalty='none', random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "source": [
    "log_reg.fit(X_filtered_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "y_proba = log_reg.predict_proba(X_filtered_test)\n",
    "y_predict = np.argmax(y_proba, axis=1)\n",
    "\n",
    "accuracy_score = np.mean(y_predict == y_test)\n",
    "accuracy_score"
   ]
  },
  {
   "source": [
    "**sepal length (cm), petal width (cm)**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered_train = X_train[:, [0, 3]]\n",
    "X_filtered_test = X_test[:, [0, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', penalty='none', random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "log_reg.fit(X_filtered_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "source": [
    "y_proba = log_reg.predict_proba(X_filtered_test)\n",
    "y_predict = np.argmax(y_proba, axis=1)\n",
    "\n",
    "accuracy_score = np.mean(y_predict == y_test)\n",
    "accuracy_score"
   ]
  },
  {
   "source": [
    "**sepal width (cm), petal length (cm)**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered_train = X_train[:, [1, 2]]\n",
    "X_filtered_test = X_test[:, [1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', penalty='none', random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "source": [
    "log_reg.fit(X_filtered_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "metadata": {},
     "execution_count": 118
    }
   ],
   "source": [
    "y_proba = log_reg.predict_proba(X_filtered_test)\n",
    "y_predict = np.argmax(y_proba, axis=1)\n",
    "\n",
    "accuracy_score = np.mean(y_predict == y_test)\n",
    "accuracy_score"
   ]
  },
  {
   "source": [
    "**sepal width (cm), petal width (cm)**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered_train = X_train[:, [1, 3]]\n",
    "X_filtered_test = X_test[:, [1, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', penalty='none', random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "source": [
    "log_reg.fit(X_filtered_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "source": [
    "y_proba = log_reg.predict_proba(X_filtered_test)\n",
    "y_predict = np.argmax(y_proba, axis=1)\n",
    "\n",
    "accuracy_score = np.mean(y_predict == y_test)\n",
    "accuracy_score"
   ]
  },
  {
   "source": [
    "**petal length (cm), petal width (cm)**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered_train = X_train[:, [2, 3]]\n",
    "X_filtered_test = X_test[:, [2, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', penalty='none', random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 124
    }
   ],
   "source": [
    "log_reg.fit(X_filtered_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 125
    }
   ],
   "source": [
    "y_proba = log_reg.predict_proba(X_filtered_test)\n",
    "y_predict = np.argmax(y_proba, axis=1)\n",
    "\n",
    "accuracy_score = np.mean(y_predict == y_test)\n",
    "accuracy_score"
   ]
  },
  {
   "source": [
    "Feature             | sepal length (cm) | sepal width (cm)  | petal length (cm) | petal width (cm)  |\n",
    ":-------------------| ------------------| ------------------| ------------------| ------------------|\n",
    "sepal length (cm)   | x                 | 0.8222            | 0.9777            | 1                 |\n",
    "sepal width (cm)    | x                 | x                 | 0.9777            | 0.9777            |\n",
    "petal length (cm)   | x                 | x                 | x                 | 1                 |\n",
    "petal width (cm)    | x                 | x                 | x                 | x                 |\n",
    "\n",
    "From those results, we can confirm petal width is the most successful feature, in combination with sepal and petal length, for LogisticRegression, **without any penalization**."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Triple feature classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**sepal length (cm), sepal width (cm), petal length (cm)**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered_train = X_train[:, [0, 1, 2]]\n",
    "X_filtered_test = X_test[:, [0, 1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', penalty='none', random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 127
    }
   ],
   "source": [
    "log_reg.fit(X_filtered_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "metadata": {},
     "execution_count": 128
    }
   ],
   "source": [
    "y_proba = log_reg.predict_proba(X_filtered_test)\n",
    "y_predict = np.argmax(y_proba, axis=1)\n",
    "\n",
    "accuracy_score = np.mean(y_predict == y_test)\n",
    "accuracy_score"
   ]
  },
  {
   "source": [
    "**sepal length (cm), sepal width (cm), petal width (cm)**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered_train = X_train[:, [0, 1, 3]]\n",
    "X_filtered_test = X_test[:, [0, 1, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', penalty='none', random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 130
    }
   ],
   "source": [
    "log_reg.fit(X_filtered_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "metadata": {},
     "execution_count": 131
    }
   ],
   "source": [
    "y_proba = log_reg.predict_proba(X_filtered_test)\n",
    "y_predict = np.argmax(y_proba, axis=1)\n",
    "\n",
    "accuracy_score = np.mean(y_predict == y_test)\n",
    "accuracy_score"
   ]
  },
  {
   "source": [
    "**sepal width (cm), petal length (cm), petal width (cm)**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered_train = X_train[:, [1, 2, 3]]\n",
    "X_filtered_test = X_test[:, [1, 2, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', penalty='none', random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "source": [
    "log_reg.fit(X_filtered_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 134
    }
   ],
   "source": [
    "y_proba = log_reg.predict_proba(X_filtered_test)\n",
    "y_predict = np.argmax(y_proba, axis=1)\n",
    "\n",
    "accuracy_score = np.mean(y_predict == y_test)\n",
    "accuracy_score"
   ]
  },
  {
   "source": [
    "**petal length (cm), petal width (cm), sepal length (cm)**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered_train = X_train[:, [2, 3, 0]]\n",
    "X_filtered_test = X_test[:, [2, 3, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', penalty='none', random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 136
    }
   ],
   "source": [
    "log_reg.fit(X_filtered_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 137
    }
   ],
   "source": [
    "y_proba = log_reg.predict_proba(X_filtered_test)\n",
    "y_predict = np.argmax(y_proba, axis=1)\n",
    "\n",
    "accuracy_score = np.mean(y_predict == y_test)\n",
    "accuracy_score"
   ]
  },
  {
   "source": [
    "**sepal length (cm), petal length (cm), petal width (cm)**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered_train = X_train[:, [1, 2, 3]]\n",
    "X_filtered_test = X_test[:, [1, 2, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', penalty='none', random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 139
    }
   ],
   "source": [
    "log_reg.fit(X_filtered_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 140
    }
   ],
   "source": [
    "y_proba = log_reg.predict_proba(X_filtered_test)\n",
    "y_predict = np.argmax(y_proba, axis=1)\n",
    "\n",
    "accuracy_score = np.mean(y_predict == y_test)\n",
    "accuracy_score"
   ]
  },
  {
   "source": [
    "From those results, we can't confirm which triple combination works better. We can notice that petal length and width combined are better."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Penalty "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### L1 "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='ovr', penalty='l1', random_state=42,\n",
       "                   solver='liblinear')"
      ]
     },
     "metadata": {},
     "execution_count": 142
    }
   ],
   "source": [
    "log_reg = LogisticRegression(multi_class=\"ovr\", solver=\"liblinear\", random_state=42, penalty=\"l1\")\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 143
    }
   ],
   "source": [
    "y_proba = log_reg.predict_proba(X_test)\n",
    "y_predict = np.argmax(y_proba, axis=1)\n",
    "\n",
    "accuracy_score = np.mean(y_predict == y_test)\n",
    "accuracy_score"
   ]
  },
  {
   "source": [
    "### L2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='ovr', random_state=42, solver='liblinear')"
      ]
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "source": [
    "log_reg = LogisticRegression(multi_class=\"ovr\", solver=\"liblinear\", random_state=42, penalty=\"l2\")\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "metadata": {},
     "execution_count": 146
    }
   ],
   "source": [
    "y_proba = log_reg.predict_proba(X_test)\n",
    "y_predict = np.argmax(y_proba, axis=1)\n",
    "\n",
    "accuracy_score = np.mean(y_predict == y_test)\n",
    "accuracy_score"
   ]
  },
  {
   "source": [
    "### Elasticnet"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(l1_ratio=0.01, max_iter=4000, multi_class='ovr',\n",
       "                   penalty='elasticnet', random_state=42, solver='saga')"
      ]
     },
     "metadata": {},
     "execution_count": 160
    }
   ],
   "source": [
    "log_reg = LogisticRegression(multi_class=\"ovr\", solver=\"saga\", random_state=42, penalty=\"elasticnet\", l1_ratio=0.01, max_iter=4000)\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "metadata": {},
     "execution_count": 161
    }
   ],
   "source": [
    "y_proba = log_reg.predict_proba(X_test)\n",
    "y_predict = np.argmax(y_proba, axis=1)\n",
    "\n",
    "accuracy_score = np.mean(y_predict == y_test)\n",
    "accuracy_score"
   ]
  },
  {
   "source": [
    "L1  | L2        | Elasticnet    | None  |\n",
    ":---|-----------| --------------|-------|\n",
    "1.0 | 0.9777    | 0.9555        | 1.0   |\n",
    "\n",
    "From those results, we can have good results without penalization. Also, L1 works just fine."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}